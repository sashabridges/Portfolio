<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <title>Sasha Bridges' Portfolio</title>
  <!-- Bring in our bootstrap stylesheet -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
  <link rel="stylesheet" href="style.css">
  </head>

<body>

<div class="topnav">
  <a class="active" href="index.html">Home</a>
  <a href="another_page.html">Portfolio</a>
  <a href="about.html">About</a>
  <a href="contact.html">Contact</a>
  <a href="visualizations.html">Visualizations Landing</a>
  <a href="comparison.html">Comparisons</a>
  <a href="data.html">Data Table</a>
	<div class="btn-group dropright">
	  <button type="button" class="btn btn-secondary dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false" style="background-color:purple; color:white;">
		Plots
	  </button>
	  <div class="dropdown-menu" z-index="1070;">
		<a href="cloudiness.html">Cloudiness</a>
		<a href="humidity.html">Humidity</a>
		<a href="temp.html">Temperature</a>
		<a href="wind_speed.html">Wind Speed</a>
	  </div>
	</div>

  <div class="login-container">
    <form action="/action_page.php">
      <input type="text" placeholder="Username" name="username">
      <input type="text" placeholder="Password" name="psw">
      <button type="submit">Login</button>
    </form>
  </div>
</div>
<!-- END NAVBAR -->
<div class="container-fluid">
<div class="main_body">
<!--- CONTENT HERE --->

<p>GottaScrapeEmAll is a group ETL project that scrapes data from the Serebii.net website and the Pokeapi.co api and transforms them into a Pandas Data Frame before loading them into a SQLite database.</p>

<p>If you want to try this code out yourself, go to <a href="https://github.com/sashabridges/ScrapeMon">github</a> and download the project.</p>

<pre><code>
# Dependencies
import os
from splinter import Browser
from bs4 import BeautifulSoup as bs
import requests
import pymongo
import pandas as pd
import csv
import requests
from sqlalchemy import create_engine
</code>
</pre>

<pre><code>
# EVERYONE ELSE USE THIS CONNECTION
executable_path = {'executable_path': 'chromedriver.exe'}
browser = Browser('chrome', **executable_path, headless=False)
</code></pre>

<p>Not all computers are created equal, and the Mac vs Windows divide is present in this project. Tad was on a Mac, so he had to use a different way to use the chromedriver. Everyone else had to use the above code.</p>

<pre><code>
url = 'https://www.serebii.net/pokedex-sm/001.shtml'
response = requests.get(url)
soup = bs(response.text, 'html.parser')
#print(soup.prettify())
</code></pre>

<p>First, we started with Serebiinet. Uncomment the print statement to see what soup returns. Careful - it's long!</p>

<pre><code>
# This will hold ALLLLLLLLLLLLL the Pokemon
total_list = []
name_w = []
alt_name = []
dex_data = []
gender_ratio = []
classification = []
height_w = []
weight_w = []
base_exp_w = []
egg_steps = []
abilities_w = []
growth = []
base_happiness = []
ev_values = []
flavor_text = []
</code></pre>

<p>Note: The data is held in array, so you have to figure out which parts of the array to keep. After deciding which parts of the data are useful through viewing the array, you can use the above code to seperate the data into columns.</p>
<p><img src="https://i.imgur.com/vXOsdVN.png"></p>

<pre><code>
url_base = 'https://www.serebii.net/pokedex-sm/'
url_end = '.shtml'
a = '0'
b = '0'
query_url = ''
total_list = []

for x in range(1, 152):
    if x < 10:
        query_url = url_base + a + b + str(x) + url_end
    if x > 10 and x < 100:
        query_url = url_base + a + str(x) + url_end
    response = requests.get(query_url)
    soup = bs(response.text, 'html.parser')
    
    final_result = soup.find_all('td', class_='fooinfo')
    p_data = []
    
    for result in final_result:
        try:
            txt = result.text

            p_data.append(txt)
        except AttributeError as e:
            pass
    print(x)

    name_w.append(p_data[1])
    alt_name.append(p_data[2])
    dex_data.append(p_data[3])
    gender_ratio.append(p_data[4])
    classification.append(p_data[5])
    height_w.append(p_data[6])
    weight_w.append(p_data[7])
    base_exp_w.append(p_data[8])
    egg_steps.append(p_data[9])
    abilities_w.append(p_data[10])
    growth.append(p_data[11])
    base_happiness.append(p_data[12])
    ev_values.append(p_data[13])
    flavor_text.append(p_data[23])
</code></pre>

<pre><code>
web_data = {'Name': name_w, 'Alternate Name': alt_name, 'Dex Data': dex_data, 'Gender Ratio': gender_ratio, 'Classification': classification,
           'Height': height_w, 'Weight': weight_w, 'Base Experience': base_exp_w, 'Hatch Egg Steps': egg_steps, 'Abilities': abilities_w, 
           'Growth Rate': growth, 'Base Happiness': base_happiness, 'EV Values': ev_values, 'Flavor Text': flavor_text}
web_df = pd.DataFrame(web_data)
web_df.head()
</code></pre>
<p>Below is an example of the DataFrame made through Serebii.</p>
<p>As you can see, obtaining the Flavor Text isn't perfect since this quick and dirty solution just gets the 23rd element of the array.</p>
<p><img src="https://i.imgur.com/DNJeEYz.png"></p>

<pre><code>
# FOR POKE-API
# https://pokeapi.co/
api_name = []
api_type = []
api_type2 = []
id_no = []
speed = []
spdef = []
spatk = []
dfn = []
atk = []
hp = []
weight = []
base_exp = []
back_sprite = []
back_shiny = []
front_sprite = []
front_shiny = []
ability_one = []
ability_two = []
url = 'https://pokeapi.co/api/v2/'
query_url = url + 'pokemon/'

for index in range(1, 152):
    response = requests.get(query_url + str(index)).json()
    try:
        api_name.append(response['species']['name'])
        api_type.append(response['types'][0]['type']['name'])
        id_no.append(response['id'])
        speed.append(response['stats'][0]['base_stat'])
        spdef.append(response['stats'][1]['base_stat'])
        spatk.append(response['stats'][2]['base_stat'])
        dfn.append(response['stats'][3]['base_stat'])
        atk.append(response['stats'][4]['base_stat'])
        hp.append(response['stats'][5]['base_stat'])
        weight.append(response['weight'])
        base_exp.append(response['base_experience'])
        back_sprite.append(response['sprites']['back_default'])
        back_shiny.append(response['sprites']['back_shiny'])
        front_sprite.append(response['sprites']['front_default'])
        front_shiny.append(response['sprites']['front_shiny'])
        api_type2.append(response['types'][1]['type']['name'])
        ability_one.append(response['abilities'][0]['ability']['name'])
        ability_two.append(response['abilities'][1]['ability']['name'])
        
        print(response['species']['name'])
        
    except:
        if (len(api_type2) < len(api_type)):
            api_type2.append('No Second Type')
        if (len(ability_one) < len(api_type)):
            ability_one.append(response['abilities'][0]['ability']['name'])
        print('No Second Type ' + response['species']['name'])
        try:
            ability_two.append(response['abilities'][1]['ability']['name'])
            print('Second Ability ' + response['species']['name'])
        except:
            ability_two.append('No Second Ability')
            print('No Second Ability ' + response['species']['name'])
</code></pre>

<pre><code>
api_data = {'Name1': api_name, 'Type 1': api_type, 'Type 2': api_type2, 'Number': id_no, 'Speed': speed,
           'Special Def': spdef, 'Special Atk': spatk, 'Defense': dfn, 'Attack': atk, 'HP': hp, 'Weight': weight,
           'Base Experience': base_exp, 'Ability One': ability_one, 'Ability Two': ability_two, 'Back Sprite': back_sprite,
           'Back Shiny': back_shiny, 'Front Sprite': front_sprite, 'Front Shiny': front_shiny}
api_df = pd.DataFrame(api_data)

api_df
</code></pre>
<p>Below is a DataFrame made by Pokeapi.</p>
<p><img src="https://i.imgur.com/vBGa99q.png"></p>

<pre><code>
web_data = {'Name2': name_w, 'Classification': classification,
           'Base Experience': base_exp_w, 'Hatch Egg Steps': egg_steps, 
            'Base Happiness': base_happiness, 'EV Values': ev_values, 
            'Flavor Text': flavor_text}
web_df = pd.DataFrame(web_data)
web_df.head(151)
</code></pre>

<pre><code>
engine0 = create_engine('sqlite://', echo=False)
#conn = engine.connect()
</code></pre>

<pre><code>
api_df.to_sql('pokemon_1', con=engine0, if_exists='replace')
</code></pre>

<pre><code>
# Run to check data has been imported
engine0.execute("select * from pokemon_1").fetchall()
</code></pre>

<pre><code>
web_df.to_sql('pokemon_2', con=engine0, if_exists='replace')
</code></pre>

<pre><code>
# Run to check data has been imported
engine0.execute("select * from pokemon_2").fetchall()
</code></pre>

<p>Fetch the data from SQLite and make sure it's all correct.</p>
<p><img src="https://i.imgur.com/bvUrmWQ.png"></p>

<pre><code>
# Create a database on MySQL
# then connect to local database 
rds_connection_string = "root:Tats3388@127.0.0.1/pokemon"
engine1 = create_engine(f'mysql://{rds_connection_string}')

# Check for tables
engine1.table_names()
</code></pre>

<pre><code>
api_df.to_sql(name='api_df', con=engine1, if_exists='replace')
</code></pre>

<pre><code>
# Confirm data has been added by querying the pokemon_db table
pd.read_sql_query('select * from api_df', con=engine1)
</code></pre>

<pre><code>
web_df1.to_sql(name='web_df1', con=engine1, if_exists='replace')
</code></pre>

<pre><code>
pd.read_sql_query('select * from web_df1', con=engine1)
</code></pre>

<pre><code>
pd.read_sql_query("select *\
                    from api_df a\
                    join web_df w\
                    on a.Name = w.Name", con=engine1)
</code></pre>

<p>Finally, check to see if the join is possible.</p>
<p><img src="https://i.imgur.com/ZA4iRBN.png"></p>
</div>


<!--- END CONTENT --->
</div>

</div>
<div id="footer">
<hr>
<p>Sasha Bridges, 2019</p>
<hr>
</div>
</body>
</html>